"""
Search node implementation
Responsible for generating search queries and reflection queries
"""

import json
from typing import Dict, Any
from json.decoder import JSONDecodeError
from loguru import logger

from .base_node import BaseNode
from ..prompts import SYSTEM_PROMPT_FIRST_SEARCH, SYSTEM_PROMPT_REFLECTION
from ..utils.text_processing import (
    remove_reasoning_from_output,
    clean_json_tags,
    extract_clean_response,
    fix_incomplete_json
)


class FirstSearchNode(BaseNode):
    """Node for generating first search query for a paragraph"""

    def __init__(self, llm_client):
        """
        Initialize first search node

        Args:
            llm_client: LLM client
        """
        super().__init__(llm_client, "FirstSearchNode")
    
    def validate_input(self, input_data: Any) -> bool:
        """Validate input data"""
        if isinstance(input_data, str):
            try:
                data = json.loads(input_data)
                return "title" in data and "content" in data
            except JSONDecodeError:
                return False
        elif isinstance(input_data, dict):
            return "title" in input_data and "content" in input_data
        return False

    def run(self, input_data: Any, **kwargs) -> Dict[str, str]:
        """
        Call LLM to generate search query and reasoning

        Args:
            input_data: String or dict containing title and content
            **kwargs: Additional parameters

        Returns:
            Dict containing search_query and reasoning
        """
        try:
            if not self.validate_input(input_data):
                raise ValueError("Input data format error, must contain title and content fields")

            # Prepare input data
            if isinstance(input_data, str):
                message = input_data
            else:
                message = json.dumps(input_data, ensure_ascii=False)

            logger.info("Generating first search query")

            # Call LLM
            response = self.llm_client.stream_invoke_to_string(SYSTEM_PROMPT_FIRST_SEARCH, message)

            # Process response
            processed_response = self.process_output(response)

            logger.info(f"Generated search query: {processed_response.get('search_query', 'N/A')}")
            return processed_response

        except Exception as e:
            logger.exception(f"Failed to generate first search query: {str(e)}")
            raise e
    
    def process_output(self, output: str) -> Dict[str, str]:
        """
        Process LLM output, extract search query and reasoning

        Args:
            output: Raw LLM output

        Returns:
            Dict containing search_query and reasoning
        """
        try:
            # Clean response text
            cleaned_output = remove_reasoning_from_output(output)
            cleaned_output = clean_json_tags(cleaned_output)

            # Log cleaned output for debugging
            logger.info(f"Cleaned output: {cleaned_output}")

            # Parse JSON
            try:
                result = json.loads(cleaned_output)
                logger.info("JSON parsing successful")
            except JSONDecodeError as e:
                logger.error(f"JSON parsing failed: {str(e)}")
                # Use more powerful extraction method
                result = extract_clean_response(cleaned_output)
                if "error" in result:
                    logger.error("JSON parsing failed, attempting to fix...")
                    # Try to fix JSON
                    fixed_json = fix_incomplete_json(cleaned_output)
                    if fixed_json:
                        try:
                            result = json.loads(fixed_json)
                            logger.info("JSON fix successful")
                        except JSONDecodeError:
                            logger.error("JSON fix failed")
                            # Return default query
                            return self._get_default_search_query()
                    else:
                        logger.error("Unable to fix JSON, using default query")
                        return self._get_default_search_query()

            # Validate and clean result
            search_query = result.get("search_query", "")
            reasoning = result.get("reasoning", "")

            if not search_query:
                logger.warning("Search query not found, using default query")
                return self._get_default_search_query()

            return {
                "search_query": search_query,
                "reasoning": reasoning
            }

        except Exception as e:
            self.log_error(f"Failed to process output: {str(e)}")
            # Return default query
            return self._get_default_search_query()

    def _get_default_search_query(self) -> Dict[str, str]:
        """
        Get default search query

        Returns:
            Default search query dict
        """
        return {
            "search_query": "Related topic research",
            "reasoning": "Using default search query due to parsing failure"
        }


class ReflectionNode(BaseNode):
    """Node for reflecting on paragraph and generating new search query"""

    def __init__(self, llm_client):
        """
        Initialize reflection node

        Args:
            llm_client: LLM client
        """
        super().__init__(llm_client, "ReflectionNode")

    def validate_input(self, input_data: Any) -> bool:
        """Validate input data"""
        if isinstance(input_data, str):
            try:
                data = json.loads(input_data)
                required_fields = ["title", "content", "paragraph_latest_state"]
                return all(field in data for field in required_fields)
            except JSONDecodeError:
                return False
        elif isinstance(input_data, dict):
            required_fields = ["title", "content", "paragraph_latest_state"]
            return all(field in input_data for field in required_fields)
        return False

    def run(self, input_data: Any, **kwargs) -> Dict[str, str]:
        """
        Call LLM to reflect and generate search query

        Args:
            input_data: String or dict containing title, content and paragraph_latest_state
            **kwargs: Additional parameters

        Returns:
            Dict containing search_query and reasoning
        """
        try:
            if not self.validate_input(input_data):
                raise ValueError("Input data format error, must contain title, content and paragraph_latest_state fields")

            # Prepare input data
            if isinstance(input_data, str):
                message = input_data
            else:
                message = json.dumps(input_data, ensure_ascii=False)

            logger.info("Performing reflection and generating new search query")

            # Call LLM
            response = self.llm_client.stream_invoke_to_string(SYSTEM_PROMPT_REFLECTION, message)

            # Process response
            processed_response = self.process_output(response)

            logger.info(f"Reflection generated search query: {processed_response.get('search_query', 'N/A')}")
            return processed_response

        except Exception as e:
            logger.exception(f"Failed to generate reflection search query: {str(e)}")
            raise e
    
    def process_output(self, output: str) -> Dict[str, str]:
        """
        Process LLM output, extract search query and reasoning

        Args:
            output: Raw LLM output

        Returns:
            Dict containing search_query and reasoning
        """
        try:
            # Clean response text
            cleaned_output = remove_reasoning_from_output(output)
            cleaned_output = clean_json_tags(cleaned_output)

            # Log cleaned output for debugging
            logger.info(f"Cleaned output: {cleaned_output}")

            # Parse JSON
            try:
                result = json.loads(cleaned_output)
                logger.info("JSON parsing successful")
            except JSONDecodeError as e:
                logger.error(f"JSON parsing failed: {str(e)}")
                # Use more powerful extraction method
                result = extract_clean_response(cleaned_output)
                if "error" in result:
                    logger.error("JSON parsing failed, attempting to fix...")
                    # Try to fix JSON
                    fixed_json = fix_incomplete_json(cleaned_output)
                    if fixed_json:
                        try:
                            result = json.loads(fixed_json)
                            logger.info("JSON fix successful")
                        except JSONDecodeError:
                            logger.error("JSON fix failed")
                            # Return default query
                            return self._get_default_reflection_query()
                    else:
                        logger.error("Unable to fix JSON, using default query")
                        return self._get_default_reflection_query()

            # Validate and clean result
            search_query = result.get("search_query", "")
            reasoning = result.get("reasoning", "")

            if not search_query:
                logger.warning("Search query not found, using default query")
                return self._get_default_reflection_query()

            return {
                "search_query": search_query,
                "reasoning": reasoning
            }

        except Exception as e:
            logger.exception(f"Failed to process output: {str(e)}")
            # Return default query
            return self._get_default_reflection_query()

    def _get_default_reflection_query(self) -> Dict[str, str]:
        """
        Get default reflection search query

        Returns:
            Default reflection search query dict
        """
        return {
            "search_query": "Deep research supplementary information",
            "reasoning": "Using default reflection search query due to parsing failure"
        }

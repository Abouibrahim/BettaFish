# -*- coding: utf-8 -*-
"""
Unified sentiment analysis prediction program
Supports loading all models for sentiment prediction
"""
import argparse
import os
import re
from typing import Dict, Tuple, List
import warnings
warnings.filterwarnings("ignore")

# Import all model classes
from bayes_train import BayesModel
from svm_train import SVMModel
from xgboost_train import XGBoostModel
from lstm_train import LSTMModel
from bert_train import BertModel_Custom
from utils import processing


class SentimentPredictor:
    """Sentiment analysis predictor"""
    
    def __init__(self):
        self.models = {}
        self.available_models = {
            'bayes': BayesModel,
            'svm': SVMModel,
            'xgboost': XGBoostModel,
            'lstm': LSTMModel,
            'bert': BertModel_Custom
        }
        
    def load_model(self, model_type: str, model_path: str, **kwargs) -> None:
        """Load specified type of model

        Args:
            model_type: Model type ('bayes', 'svm', 'xgboost', 'lstm', 'bert')
            model_path: Model file path
            **kwargs: Other parameters (such as BERT pretrained model path)
        """
        if model_type not in self.available_models:
            raise ValueError(f"Unsupported model type: {model_type}")

        if not os.path.exists(model_path):
            print(f"Warning: Model file does not exist: {model_path}")
            return

        print(f"Loading {model_type.upper()} model...")

        try:
            if model_type == 'bert':
                # BERT requires additional pretrained model path
                bert_path = kwargs.get('bert_path', './model/chinese_wwm_pytorch')
                model = BertModel_Custom(bert_path)
            else:
                model = self.available_models[model_type]()

            model.load_model(model_path)
            self.models[model_type] = model
            print(f"{model_type.upper()} model loaded successfully")

        except Exception as e:
            print(f"Failed to load {model_type.upper()} model: {e}")
    
    def load_all_models(self, model_dir: str = './model', bert_path: str = './model/chinese_wwm_pytorch') -> None:
        """åŠ è½½æ‰€æœ‰å¯ç”¨çš„æ¨¡åž‹
        
        Args:
            model_dir: æ¨¡åž‹æ–‡ä»¶ç›®å½•
            bert_path: BERTé¢„è®­ç»ƒæ¨¡åž‹è·¯å¾„
        """
        model_files = {
            'bayes': os.path.join(model_dir, 'bayes_model.pkl'),
            'svm': os.path.join(model_dir, 'svm_model.pkl'),
            'xgboost': os.path.join(model_dir, 'xgboost_model.pkl'),
            'lstm': os.path.join(model_dir, 'lstm_model.pth'),
            'bert': os.path.join(model_dir, 'bert_model.pth')
        }
        
        print("å¼€å§‹åŠ è½½æ‰€æœ‰å¯ç”¨æ¨¡åž‹...")
        for model_type, model_path in model_files.items():
            self.load_model(model_type, model_path, bert_path=bert_path)
        
        print(f"\nå·²åŠ è½½ {len(self.models)} ä¸ªæ¨¡åž‹: {list(self.models.keys())}")
    
    def predict_single(self, text: str, model_type: str = None) -> Dict[str, Tuple[int, float]]:
        """é¢„æµ‹å•æ¡æ–‡æœ¬çš„æƒ…æ„Ÿ
        
        Args:
            text: å¾…é¢„æµ‹æ–‡æœ¬
            model_type: æŒ‡å®šæ¨¡åž‹ç±»åž‹ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å·²åŠ è½½çš„æ¨¡åž‹
            
        Returns:
            Dict[model_type, (prediction, confidence)]
        """
        # æ–‡æœ¬é¢„å¤„ç†
        processed_text = processing(text)
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡åž‹ {model_type} æœªåŠ è½½")
            
            prediction, confidence = self.models[model_type].predict_single(processed_text)
            return {model_type: (prediction, confidence)}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡åž‹é¢„æµ‹
        results = {}
        for name, model in self.models.items():
            try:
                prediction, confidence = model.predict_single(processed_text)
                results[name] = (prediction, confidence)
            except Exception as e:
                print(f"æ¨¡åž‹ {name} é¢„æµ‹å¤±è´¥: {e}")
                results[name] = (0, 0.0)
        
        return results
    
    def predict_batch(self, texts: List[str], model_type: str = None) -> Dict[str, List[int]]:
        """æ‰¹é‡é¢„æµ‹æ–‡æœ¬æƒ…æ„Ÿ
        
        Args:
            texts: å¾…é¢„æµ‹æ–‡æœ¬åˆ—è¡¨
            model_type: æŒ‡å®šæ¨¡åž‹ç±»åž‹ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨æ‰€æœ‰å·²åŠ è½½çš„æ¨¡åž‹
            
        Returns:
            Dict[model_type, predictions]
        """
        # æ–‡æœ¬é¢„å¤„ç†
        processed_texts = [processing(text) for text in texts]
        
        if model_type:
            if model_type not in self.models:
                raise ValueError(f"æ¨¡åž‹ {model_type} æœªåŠ è½½")
            
            predictions = self.models[model_type].predict(processed_texts)
            return {model_type: predictions}
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡åž‹é¢„æµ‹
        results = {}
        for name, model in self.models.items():
            try:
                predictions = model.predict(processed_texts)
                results[name] = predictions
            except Exception as e:
                print(f"æ¨¡åž‹ {name} é¢„æµ‹å¤±è´¥: {e}")
                results[name] = [0] * len(texts)
        
        return results
    
    def ensemble_predict(self, text: str, weights: Dict[str, float] = None) -> Tuple[int, float]:
        """é›†æˆé¢„æµ‹ï¼ˆå¤šä¸ªæ¨¡åž‹æŠ•ç¥¨ï¼‰
        
        Args:
            text: å¾…é¢„æµ‹æ–‡æœ¬
            weights: æ¨¡åž‹æƒé‡ï¼Œå¦‚æžœä¸ºNoneåˆ™å¹³å‡æƒé‡
            
        Returns:
            (prediction, confidence)
        """
        if len(self.models) == 0:
            raise ValueError("æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡åž‹")
        
        results = self.predict_single(text)
        
        if weights is None:
            weights = {name: 1.0 for name in results.keys()}
        
        # åŠ æƒå¹³å‡
        total_weight = 0
        weighted_prob = 0
        
        for model_name, (pred, conf) in results.items():
            if model_name in weights:
                weight = weights[model_name]
                prob = conf if pred == 1 else 1 - conf
                weighted_prob += prob * weight
                total_weight += weight
        
        if total_weight == 0:
            return 0, 0.5
        
        final_prob = weighted_prob / total_weight
        final_pred = int(final_prob > 0.5)
        final_conf = final_prob if final_pred == 1 else 1 - final_prob
        
        return final_pred, final_conf
    
    def interactive_predict(self):
        """äº¤äº’å¼é¢„æµ‹æ¨¡å¼"""
        if len(self.models) == 0:
            print("é”™è¯¯: æ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡åž‹ï¼Œè¯·å…ˆåŠ è½½æ¨¡åž‹")
            return
        
        print("\n" + "="*50)
        print("="*50)
        print(f"å·²åŠ è½½æ¨¡åž‹: {', '.join(self.models.keys())}")
        print("è¾“å…¥ 'q' é€€å‡ºç¨‹åº")
        print("è¾“å…¥ 'models' æŸ¥çœ‹æ¨¡åž‹åˆ—è¡¨")
        print("è¾“å…¥ 'ensemble' ä½¿ç”¨é›†æˆé¢„æµ‹")
        print("-"*50)
        
        while True:
            try:
                text = input("\nè¯·è¾“å…¥è¦åˆ†æžçš„å¾®åšå†…å®¹: ").strip()
                
                if text.lower() == 'q':
                    print("ðŸ‘‹ å†è§ï¼")
                    break
                
                if text.lower() == 'models':
                    print(f"å·²åŠ è½½æ¨¡åž‹: {list(self.models.keys())}")
                    continue
                
                if text.lower() == 'ensemble':
                    if len(self.models) > 1:
                        pred, conf = self.ensemble_predict(text)
                        sentiment = "ðŸ˜Š æ­£é¢" if pred == 1 else "ðŸ˜ž è´Ÿé¢"
                        print(f"\nðŸ¤– é›†æˆé¢„æµ‹ç»“æžœ:")
                        print(f"   æƒ…æ„Ÿå€¾å‘: {sentiment}")
                        print(f"   ç½®ä¿¡åº¦: {conf:.4f}")
                    else:
                        print("âŒ é›†æˆé¢„æµ‹éœ€è¦è‡³å°‘2ä¸ªæ¨¡åž‹")
                    continue
                
                if not text:
                    print("âŒ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # é¢„æµ‹
                results = self.predict_single(text)
                
                print(f"\nðŸ“ åŽŸæ–‡: {text}")
                print("ðŸ” é¢„æµ‹ç»“æžœ:")
                
                for model_name, (pred, conf) in results.items():
                    sentiment = "ðŸ˜Š æ­£é¢" if pred == 1 else "ðŸ˜ž è´Ÿé¢"
                    print(f"   {model_name.upper():8}: {sentiment} (ç½®ä¿¡åº¦: {conf:.4f})")
                
                # å¦‚æžœæœ‰å¤šä¸ªæ¨¡åž‹ï¼Œæ˜¾ç¤ºé›†æˆç»“æžœ
                if len(results) > 1:
                    ensemble_pred, ensemble_conf = self.ensemble_predict(text)
                    ensemble_sentiment = "ðŸ˜Š æ­£é¢" if ensemble_pred == 1 else "ðŸ˜ž è´Ÿé¢"
                    print(f"   {'é›†æˆ':8}: {ensemble_sentiment} (ç½®ä¿¡åº¦: {ensemble_conf:.4f})")
                
            except KeyboardInterrupt:
                print("\n\nðŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}")


def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='Weibo Sentiment Analysis Unified Prediction Program')
    parser.add_argument('--model_dir', type=str, default='./model',
                        help='Model file directory')
    parser.add_argument('--bert_path', type=str, default='./model/chinese_wwm_pytorch',
                        help='BERT pretrained model path')
    parser.add_argument('--model_type', type=str, choices=['bayes', 'svm', 'xgboost', 'lstm', 'bert'],
                        help='Specify single model type for prediction')
    parser.add_argument('--text', type=str,
                        help='Directly predict specified text')
    parser.add_argument('--interactive', action='store_true', default=True,
                        help='Interactive prediction mode (default)')
    parser.add_argument('--ensemble', action='store_true',
                        help='Use ensemble prediction')

    args = parser.parse_args()

    # Create predictor
    predictor = SentimentPredictor()

    # Load models
    if args.model_type:
        # Load specified model
        model_files = {
            'bayes': 'bayes_model.pkl',
            'svm': 'svm_model.pkl',
            'xgboost': 'xgboost_model.pkl',
            'lstm': 'lstm_model.pth',
            'bert': 'bert_model.pth'
        }
        model_path = os.path.join(args.model_dir, model_files[args.model_type])
        predictor.load_model(args.model_type, model_path, bert_path=args.bert_path)
    else:
        # Load all models
        predictor.load_all_models(args.model_dir, args.bert_path)

    # If text is specified, predict directly
    if args.text:
        if args.ensemble and len(predictor.models) > 1:
            pred, conf = predictor.ensemble_predict(args.text)
            sentiment = "Positive" if pred == 1 else "Negative"
            print(f"Text: {args.text}")
            print(f"Ensemble prediction: {sentiment} (Confidence: {conf:.4f})")
        else:
            results = predictor.predict_single(args.text, args.model_type)
            print(f"Text: {args.text}")
            for model_name, (pred, conf) in results.items():
                sentiment = "Positive" if pred == 1 else "Negative"
                print(f"{model_name.upper()}: {sentiment} (Confidence: {conf:.4f})")
    elif args.interactive:
        # Interactive mode
        predictor.interactive_predict()


if __name__ == "__main__":
    main()